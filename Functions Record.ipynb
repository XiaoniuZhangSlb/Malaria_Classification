{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f0bf07-bcce-49aa-8f20-7359c2f6a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# os.chdir allows you to change directories, like cd in the Terminal\n",
    "os.chdir('/home/muriel/code/XiaoniuZhangSlb/Malaria_Classification/raw_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4e923-2a75-484e-8175-e18dabac458a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Yolo files config version 1 - no categories removed. \n",
    "Note: I optimized Version 2 below further. You could skip to version 2 instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dcf5d45-06f0-45ce-b775-b38904404037",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/muriel/code/XiaoniuZhangSlb/Malaria_Classification/raw_data')\n",
    "\n",
    "def create_yoloconfig_structure(raw_data_path):\n",
    "  import pandas as pd\n",
    "  import os\n",
    "\n",
    "  os.chdir(raw_data_path)\n",
    "\n",
    "  directory = 'malaria'\n",
    "  yolo_directory = \"vivax_yolo_config\"\n",
    "  images_directory =  \"images\"\n",
    "  train_directory = \"train\"\n",
    "  val_directory = \"val\"\n",
    "  test_directory = \"test\"\n",
    "  labels_directory = \"labels\"\n",
    "\n",
    "  rootpath = os.path.join(raw_data_path, directory)\n",
    "  yolopath = os.path.join(rootpath, yolo_directory)\n",
    "\n",
    "  yolo_images_path =  os.path.join(yolopath, images_directory)\n",
    "  yolo_train_images_path = os.path.join(yolo_images_path, train_directory)\n",
    "  yolo_val_images_path = os.path.join(yolo_images_path, val_directory)\n",
    "    \n",
    "  yolo_test_images_path = os.path.join(yolo_images_path, test_directory)\n",
    "  yolo_labels_path = os.path.join(yolopath, labels_directory)\n",
    "  yolo_train_labels_path = os.path.join(yolo_labels_path, train_directory)\n",
    "  yolo_val_labels_path = os.path.join(yolo_labels_path, val_directory)\n",
    "  yolo_test_labels_path = os.path.join(yolo_labels_path, test_directory)\n",
    "\n",
    "  if not os.path.exists(yolo_labels_path):\n",
    "      os.makedirs(yolo_labels_path)\n",
    "\n",
    "  if not os.path.exists(yolo_train_images_path):\n",
    "      os.makedirs(yolo_train_images_path)\n",
    "\n",
    "  if not os.path.exists(yolo_val_images_path):\n",
    "      os.makedirs(yolo_val_images_path)\n",
    "      \n",
    "  if not os.path.exists(yolo_test_images_path):\n",
    "      os.makedirs(yolo_test_images_path)\n",
    "\n",
    "  if not os.path.exists(yolo_train_labels_path):\n",
    "      os.makedirs(yolo_train_labels_path)\n",
    "\n",
    "  if not os.path.exists(yolo_val_labels_path):\n",
    "      os.makedirs(yolo_val_labels_path)\n",
    "    \n",
    "  if not os.path.exists(yolo_test_labels_path):\n",
    "      os.makedirs(yolo_test_labels_path)\n",
    "\n",
    "  # Creating the yaml file\n",
    "  doc = open(os.path.join(yolopath, 'vivax.yaml'), 'w')\n",
    "\n",
    "  doc.write(f'path: {yolopath}')\n",
    "  doc.write('\\n')\n",
    "  doc.write(f'train: {os.path.relpath(yolo_train_images_path, yolopath)}')\n",
    "  doc.write('\\n')\n",
    "  doc.write(f'val: {os.path.relpath(yolo_val_images_path, yolopath)}')\n",
    "  doc.write('\\n')\n",
    "  doc.write(f'test: {os.path.relpath(yolo_test_images_path, yolopath)}')\n",
    "  doc.write('\\n')\n",
    "  doc.write('names:')\n",
    "  doc.write('\\n')\n",
    "  names_lines = ['  0: red blood cell', '  1: leukocyte', '  2: gametocyte', '  3: ring', '  4: trophozoite', '  5: schizont', '  6: difficult']\n",
    "  for line in names_lines:\n",
    "    doc.write(line)\n",
    "    doc.write('\\n')\n",
    "\n",
    "  doc.close()\n",
    "\n",
    "  return yolopath, yolo_labels_path, yolo_train_images_path, yolo_val_images_path, yolo_test_images_path, yolo_train_labels_path, yolo_val_labels_path, yolo_test_labels_path, doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad812a97-b89b-4fd6-8215-8e7caeb2331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_json_to_df(jsonfiledir, jsonfilename):\n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "    \n",
    "  # Extracting txt labels from json file\n",
    "  jsonfiledir = jsonfiledir + '/'\n",
    "  readlocation = jsonfiledir + jsonfilename\n",
    "  json_df = pd.read_json(readlocation)\n",
    "  json_df['path'] = json_df['image'].map(lambda x: jsonfiledir + x['pathname'][1:])\n",
    "  json_df['shape'] = json_df['image'].map(lambda x: x['shape'])\n",
    "\n",
    "  json_object_df = pd.DataFrame([dict(image=c_row['path'], shape=c_row['shape'], **c_item) for _, c_row in json_df.iterrows() for c_item in c_row['objects']])\n",
    "\n",
    "  json_object_df['image_width'] = json_object_df['shape'].map(lambda x: x['c'])\n",
    "  json_object_df['image_height'] = json_object_df['shape'].map(lambda x: x['r'])\n",
    "  json_object_df['image_name'] = json_object_df['image'].map(lambda x: x.split('/', x.count(\"/\"))[-1])\n",
    "  json_object_df['class_label'] = json_object_df['category'].map({'red blood cell': 0, 'leukocyte': 1, 'gametocyte': 2, 'ring': 3, 'trophozoite': 4, 'schizont': 5, 'difficult': 6})\n",
    "\n",
    "  json_object_df['center_x'] = json_object_df['bounding_box'].map(lambda x: x['minimum']['c'] + (x['maximum']['c'] - x['minimum']['c'])/2 )\n",
    "  json_object_df['center_y'] = json_object_df['bounding_box'].map(lambda x: x['minimum']['r'] + (x['maximum']['r'] - x['minimum']['r'])/2 )\n",
    "  json_object_df['width'] = json_object_df['bounding_box'].map(lambda x: (x['maximum']['c'] - x['minimum']['c']))\n",
    "  json_object_df['height'] = json_object_df['bounding_box'].map(lambda x: (x['maximum']['r'] - x['minimum']['r']))\n",
    "\n",
    "\n",
    "  # Normalizing the values\n",
    "  json_object_df['center_x'] = json_object_df['center_x'] / json_object_df['image_width']\n",
    "  json_object_df['center_y'] = json_object_df['center_y'] / json_object_df['image_height']\n",
    "  json_object_df['width'] = json_object_df['width'] / json_object_df['image_width']\n",
    "  json_object_df['height'] = json_object_df['height'] / json_object_df['image_height']\n",
    "    \n",
    "\n",
    "  # Randomly select some of the images for validation\n",
    "  if 'train' in jsonfilename:\n",
    "        \n",
    "        # Asking for data balancing\n",
    "        balance = ''\n",
    "        \n",
    "        print(json_object_df['category'].value_counts())\n",
    "        \n",
    "        while balance != 'Y' and balance != 'N':\n",
    "            balance = input('\\n The statistics above present the categories proportion. Do you want to balance the training dataset (Y/N)?') \n",
    "        \n",
    "        #If the user opts for data balancing, the most represented class(es) proportion will be reduced to the same proportion as the less represented class.\n",
    "            if balance == 'Y':\n",
    "                json_train_df = pd.DataFrame(columns = json_object_df.columns)\n",
    "                for cat in json_object_df['category'].unique():\n",
    "                    temp_df = json_object_df[json_object_df['category']==cat].sample(n = json_object_df['category'].value_counts()[-1], replace=False)\n",
    "                    json_train_df = pd.concat([json_train_df, temp_df])\n",
    "                \n",
    "                json_val_df = json_object_df.drop(index=json_train_df.index).sample(n=round(0.3*json_train_df.shape[0]), replace=False)\n",
    "                \n",
    "            else:\n",
    "                json_val_df = json_object_df.sample(frac=0.3, replace=False)\n",
    "                json_train_df = json_object_df.copy().drop(index = json_val_df.index)\n",
    "        \n",
    "        json_test_df = pd.DataFrame({'A' : []})\n",
    "\n",
    "  elif 'test' in jsonfilename:\n",
    "      json_val_df = pd.DataFrame({'A' : []})\n",
    "      json_train_df = pd.DataFrame({'A' : []})\n",
    "      json_test_df = json_object_df.copy()\n",
    "      \n",
    "    \n",
    "  return json_train_df, json_val_df, json_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ade7d59c-5312-4686-a681-c16e83f44a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_files_config(imagesdir, jsonfiledir, jsonfilename, raw_data_path):\n",
    "  # Organizing images (train vs. test or val) and exporting them with the bounding boxes files into the corresponding yolo config files\n",
    "  json_train_df, json_val_df, json_test_df = yolo_json_to_df(jsonfiledir, jsonfilename)\n",
    "  yolopath, yolo_labels_path, yolo_train_images_path, yolo_val_images_path, yolo_test_images_path, yolo_train_labels_path, yolo_val_labels_path, yolo_test_labels_path, doc = create_yoloconfig_structure(raw_data_path)\n",
    "\n",
    "  import shutil\n",
    "  if 'train' in jsonfilename:\n",
    "    \n",
    "    for pic in json_train_df['image_name'].unique():\n",
    "        shutil.copy2(os.path.join(imagesdir, pic), yolo_train_images_path)\n",
    "        filename_save = yolo_train_labels_path + '/' + pic[:len(pic) - 3] + 'txt'\n",
    "        json_train_df[json_train_df['image_name'] == pic].iloc[:, 7:].to_csv(filename_save, header=None, index=None, sep=' ')\n",
    "\n",
    "    for pic in json_val_df['image_name'].unique():\n",
    "        shutil.copy2(os.path.join(imagesdir, pic), yolo_val_images_path)\n",
    "        filename_save = yolo_val_labels_path + '/' + pic[:len(pic) - 3] + 'txt'\n",
    "        json_val_df[json_val_df['image_name'] == pic].iloc[:, 7:].to_csv(filename_save, header=None, index=None, sep=' ')\n",
    "  \n",
    "  elif 'test' in jsonfilename:   \n",
    "        \n",
    "    for pic in json_test_df['image_name'].unique():\n",
    "        shutil.copy2(os.path.join(imagesdir, pic), yolo_test_images_path)\n",
    "        filename_save = yolo_test_labels_path + '/' + pic[:len(pic) - 3] + 'txt'\n",
    "        json_test_df[json_test_df['image_name'] == pic].iloc[:, 7:].to_csv(filename_save, header=None, index=None, sep=' ')\n",
    "\n",
    "\n",
    "  print(f\"All yolo files and folders have been created in the following location: {yolopath}. \\n Your yaml file is: {doc} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77f673-5509-43d3-afdc-9c0bf4c8b30e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Yolo files config version 2 - gives the user options for removing some cells categories from the data and creating a \"more balanced\" dataset (albeit reduced) if needed (e.g. the class \"difficult\" in this case)\n",
    "Note: in some cases, you may need to manually update the classes in the yaml file after the lines of code below have created it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed85dd66-9a6e-40a2-a4c2-dd9a79a68470",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/muriel/code/XiaoniuZhangSlb/Malaria_Classification/raw_data')\n",
    "\n",
    "def create_yoloconfig_structure(raw_data_path):\n",
    "  import pandas as pd\n",
    "  import os\n",
    "\n",
    "  os.chdir(raw_data_path)\n",
    "\n",
    "  directory = 'malaria'\n",
    "  yolo_directory = \"vivax_yolo_config\"\n",
    "  images_directory =  \"images\"\n",
    "  train_directory = \"train\"\n",
    "  val_directory = \"val\"\n",
    "  test_directory = \"test\"\n",
    "  labels_directory = \"labels\"\n",
    "\n",
    "  rootpath = os.path.join(raw_data_path, directory)\n",
    "  yolopath = os.path.join(rootpath, yolo_directory)\n",
    "\n",
    "  yolo_images_path =  os.path.join(yolopath, images_directory)\n",
    "  yolo_train_images_path = os.path.join(yolo_images_path, train_directory)\n",
    "  yolo_val_images_path = os.path.join(yolo_images_path, val_directory)\n",
    "    \n",
    "  yolo_test_images_path = os.path.join(yolo_images_path, test_directory)\n",
    "  yolo_labels_path = os.path.join(yolopath, labels_directory)\n",
    "  yolo_train_labels_path = os.path.join(yolo_labels_path, train_directory)\n",
    "  yolo_val_labels_path = os.path.join(yolo_labels_path, val_directory)\n",
    "  yolo_test_labels_path = os.path.join(yolo_labels_path, test_directory)\n",
    "\n",
    "  if not os.path.exists(yolo_labels_path):\n",
    "      os.makedirs(yolo_labels_path)\n",
    "\n",
    "  if not os.path.exists(yolo_train_images_path):\n",
    "      os.makedirs(yolo_train_images_path)\n",
    "\n",
    "  if not os.path.exists(yolo_val_images_path):\n",
    "      os.makedirs(yolo_val_images_path)\n",
    "      \n",
    "  if not os.path.exists(yolo_test_images_path):\n",
    "      os.makedirs(yolo_test_images_path)\n",
    "\n",
    "  if not os.path.exists(yolo_train_labels_path):\n",
    "      os.makedirs(yolo_train_labels_path)\n",
    "\n",
    "  if not os.path.exists(yolo_val_labels_path):\n",
    "      os.makedirs(yolo_val_labels_path)\n",
    "    \n",
    "  if not os.path.exists(yolo_test_labels_path):\n",
    "      os.makedirs(yolo_test_labels_path)\n",
    "\n",
    "  # Creating the yaml file\n",
    "  doc = open(os.path.join(yolopath, 'vivax.yaml'), 'w')\n",
    "\n",
    "  doc.write(f'path: {yolopath}')\n",
    "  doc.write('\\n')\n",
    "  doc.write(f'train: {os.path.relpath(yolo_train_images_path, yolopath)}')\n",
    "  doc.write('\\n')\n",
    "  doc.write(f'val: {os.path.relpath(yolo_val_images_path, yolopath)}')\n",
    "  doc.write('\\n')\n",
    "  doc.write(f'test: {os.path.relpath(yolo_test_images_path, yolopath)}')\n",
    "  doc.write('\\n')\n",
    "  doc.write('names:')\n",
    "  doc.write('\\n')\n",
    "  names_lines = ['  0: red blood cell', '  1: leukocyte', '  2: gametocyte', '  3: ring', '  4: trophozoite', '  5: schizont', '  6: difficult']\n",
    "  for line in names_lines:\n",
    "    doc.write(line)\n",
    "    doc.write('\\n')\n",
    "\n",
    "  doc.close()\n",
    "\n",
    "  return yolopath, yolo_labels_path, yolo_train_images_path, yolo_val_images_path, yolo_test_images_path, yolo_train_labels_path, yolo_val_labels_path, yolo_test_labels_path, doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d05296-a8b4-4925-94fa-b59260264366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removecat(df):\n",
    "    remove = ' '\n",
    "    while remove != 'Y' and remove != 'N':\n",
    "        remove = input('\\n The statistics above present the categories proportion. Would you want to completely remove some categories? (Y/N)')\n",
    "        \n",
    "    if remove == 'Y':\n",
    "        removelist=[]\n",
    "        num_remove = input('\\n How many categories do you intend to remove?')\n",
    "        while len(removelist) < int(num_remove):\n",
    "            removecat= input('\\n Please provide one of the categories you want to remove').strip(\" []' \")\n",
    "            removelist.append(removecat)\n",
    "        \n",
    "        for j in removelist:\n",
    "            if j not in list(df['category'].unique()):\n",
    "                removelist.remove(j)\n",
    "        \n",
    "        remainingcat = np.setdiff1d(list(df['category'].unique()), removelist)\n",
    "    \n",
    "    else:\n",
    "        remainingcat = df['category'].unique()\n",
    "        removelist = []\n",
    "\n",
    "    return removelist, remainingcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7612ca8a-ee9c-42af-87a2-8294e3712bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_cat_labels(df):\n",
    "    result_dict = {}\n",
    "    cat_list = list(df['category'].unique())\n",
    "\n",
    "    for j in cat_list:\n",
    "        result_dict[j]=cat_list.index(j)\n",
    "        \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8efc4514-0882-44f8-897d-5cf569eeb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_json_to_df(jsonfiledir, jsonfilename):\n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "    \n",
    "  # Extracting txt labels from json file\n",
    "  jsonfiledir = jsonfiledir + '/'\n",
    "  readlocation = jsonfiledir + jsonfilename\n",
    "  json_df = pd.read_json(readlocation)\n",
    "  json_df['path'] = json_df['image'].map(lambda x: jsonfiledir + x['pathname'][1:])\n",
    "  json_df['shape'] = json_df['image'].map(lambda x: x['shape'])\n",
    "\n",
    "  json_object_df = pd.DataFrame([dict(image=c_row['path'], shape=c_row['shape'], **c_item) for _, c_row in json_df.iterrows() for c_item in c_row['objects']])\n",
    "\n",
    "  json_object_df['image_width'] = json_object_df['shape'].map(lambda x: x['c'])\n",
    "  json_object_df['image_height'] = json_object_df['shape'].map(lambda x: x['r'])\n",
    "  json_object_df['image_name'] = json_object_df['image'].map(lambda x: x.split('/', x.count(\"/\"))[-1])\n",
    "  json_object_df['class_label'] = json_object_df['category'].map({'red blood cell': 0, 'leukocyte': 1, 'gametocyte': 2, 'ring': 3, 'trophozoite': 4, 'schizont': 5, 'difficult': 6})\n",
    "\n",
    "  json_object_df['center_x'] = json_object_df['bounding_box'].map(lambda x: x['minimum']['c'] + (x['maximum']['c'] - x['minimum']['c'])/2 )\n",
    "  json_object_df['center_y'] = json_object_df['bounding_box'].map(lambda x: x['minimum']['r'] + (x['maximum']['r'] - x['minimum']['r'])/2 )\n",
    "  json_object_df['width'] = json_object_df['bounding_box'].map(lambda x: (x['maximum']['c'] - x['minimum']['c']))\n",
    "  json_object_df['height'] = json_object_df['bounding_box'].map(lambda x: (x['maximum']['r'] - x['minimum']['r']))\n",
    "\n",
    "\n",
    "  # Normalizing the values\n",
    "  json_object_df['center_x'] = json_object_df['center_x'] / json_object_df['image_width']\n",
    "  json_object_df['center_y'] = json_object_df['center_y'] / json_object_df['image_height']\n",
    "  json_object_df['width'] = json_object_df['width'] / json_object_df['image_width']\n",
    "  json_object_df['height'] = json_object_df['height'] / json_object_df['image_height']\n",
    "    \n",
    "\n",
    "  # Randomly select some of the images for validation\n",
    "  if 'train' in jsonfilename:\n",
    "        \n",
    "        # Asking for data balancing\n",
    "        \n",
    "        \n",
    "        print(json_object_df['category'].value_counts())\n",
    "\n",
    "        remainingcat = removecat(json_object_df)[1]\n",
    "      \n",
    "        balance = ''\n",
    "        while balance != 'Y' and balance != 'N':\n",
    "            balance = input('\\n Would you want to balance the training dataset (Y/N)?') \n",
    "        \n",
    "        #If the user opts for data balancing, the most represented class(es) proportion will be reduced to the same proportion as the less represented class.\n",
    "            if balance == 'Y':\n",
    "                json_train_df = pd.DataFrame(columns = json_object_df.columns)\n",
    "                for cat in remainingcat:\n",
    "                    temp_df = json_object_df[json_object_df['category']==cat].sample(n = json_object_df['category'].value_counts()[-1], replace=False)\n",
    "                    json_train_df = pd.concat([json_train_df, temp_df])\n",
    "                \n",
    "                json_val_df = json_object_df.drop(index=json_train_df.index).sample(n=round(0.3*json_train_df.shape[0]), replace=False)\n",
    "                \n",
    "            else:\n",
    "                json_val_df = json_object_df.sample(frac=0.3, replace=False)\n",
    "                json_train_df = json_object_df.copy().drop(index = json_val_df.index)\n",
    "        \n",
    "        json_test_df = pd.DataFrame({'A' : []})\n",
    "        json_train_df['class_label'] = json_train_df['category'].map(reassign_cat_labels(json_train_df))\n",
    "        json_val_df['class_label'] = json_val_df['category'].map(reassign_cat_labels(json_val_df))\n",
    "        print(f'New classes assignment: {reassign_cat_labels(json_train_df)}')\n",
    "\n",
    "  elif 'test' in jsonfilename:\n",
    "      print(json_object_df['category'].value_counts())\n",
    "      json_val_df = pd.DataFrame({'A' : []})\n",
    "      json_train_df = pd.DataFrame({'A' : []})\n",
    "\n",
    "      remainingcat = removecat(json_object_df)[1]\n",
    "      json_test_df = pd.DataFrame(columns = json_object_df.columns)\n",
    "      \n",
    "      for cat in remainingcat:    \n",
    "          temp_df = json_object_df[json_object_df['category']==cat]\n",
    "          json_test_df = pd.concat([json_test_df, temp_df])\n",
    "              \n",
    "      json_test_df['class_label'] = json_test_df['category'].map(reassign_cat_labels(json_test_df))\n",
    "      print(f'New classes assignment: {reassign_cat_labels(json_test_df)}')\n",
    "\n",
    "\n",
    "  return json_train_df, json_val_df, json_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90ff6d4-307b-42fb-8e00-e2d43dc82a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_files_config(imagesdir, jsonfiledir, jsonfilename, raw_data_path):\n",
    "  # Organizing images (train vs. test or val) and exporting them with the bounding boxes files into the corresponding yolo config files\n",
    "  json_train_df, json_val_df, json_test_df = yolo_json_to_df(jsonfiledir, jsonfilename)\n",
    "  yolopath, yolo_labels_path, yolo_train_images_path, yolo_val_images_path, yolo_test_images_path, yolo_train_labels_path, yolo_val_labels_path, yolo_test_labels_path, doc = create_yoloconfig_structure(raw_data_path)\n",
    "\n",
    "  import shutil\n",
    "  if 'train' in jsonfilename:\n",
    "    \n",
    "    for pic in json_train_df['image_name'].unique():\n",
    "        shutil.copy2(os.path.join(imagesdir, pic), yolo_train_images_path)\n",
    "        filename_save = yolo_train_labels_path + '/' + pic[:len(pic) - 3] + 'txt'\n",
    "        json_train_df[json_train_df['image_name'] == pic].iloc[:, 7:].to_csv(filename_save, header=None, index=None, sep=' ')\n",
    "\n",
    "    for pic in json_val_df['image_name'].unique():\n",
    "        shutil.copy2(os.path.join(imagesdir, pic), yolo_val_images_path)\n",
    "        filename_save = yolo_val_labels_path + '/' + pic[:len(pic) - 3] + 'txt'\n",
    "        json_val_df[json_val_df['image_name'] == pic].iloc[:, 7:].to_csv(filename_save, header=None, index=None, sep=' ')\n",
    "  \n",
    "  elif 'test' in jsonfilename:   \n",
    "        \n",
    "    for pic in json_test_df['image_name'].unique():\n",
    "        shutil.copy2(os.path.join(imagesdir, pic), yolo_test_images_path)\n",
    "        filename_save = yolo_test_labels_path + '/' + pic[:len(pic) - 3] + 'txt'\n",
    "        json_test_df[json_test_df['image_name'] == pic].iloc[:, 7:].to_csv(filename_save, header=None, index=None, sep=' ')\n",
    "\n",
    "\n",
    "  print(f\"All yolo files and folders have been created in the following location: {yolopath}. \\n Your yaml file is: {doc} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e9f69-c050-4fa4-b4f9-7feb199c4f07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Examples Applying functions for Yolo config (with v2)\n",
    "Note: remember to adjust the input data folders according to your system configuration, before running the lines below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b5df5-8d65-475f-ae99-5c150f760795",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdir = '/home/muriel/code/XiaoniuZhangSlb/Malaria_Classification/raw_data/malaria/images'\n",
    "malaria_dir = '/home/muriel/code/XiaoniuZhangSlb/Malaria_Classification/raw_data/malaria'\n",
    "jsonfilename = 'training.json'\n",
    "raw_data_path='/home/muriel/code/XiaoniuZhangSlb/Malaria_Classification/raw_data'\n",
    "\n",
    "yolo_files_config(imdir, malaria_dir, jsonfilename, raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c7f79-f5a9-4f86-a2d9-1be9791957ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfilename = 'test.json'\n",
    "\n",
    "yolo_files_config(imdir, malaria_dir, jsonfilename, raw_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc909a-5a74-4122-9ba1-1f43cbc90831",
   "metadata": {},
   "source": [
    "## Installing Ultralytics and updating Pytorch version to overcome errors encountered during Yolo model runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88317583-b400-4afd-a920-6224222ee446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install ultralytics\n",
    "\n",
    "# from ultralytics import YOLO\n",
    "# from IPython import display\n",
    "# display.clear_output()\n",
    "# !yolo checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c23ab07f-38ff-4ba8-81d6-741c98d11395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls /usr/local |grep cuda\n",
    "# pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "# !echo $LD_LIBRARY_PATH ##checking for /usr/local/cuda/lib64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb485c2-fdd0-4b67-b7aa-f8c37432eae2",
   "metadata": {},
   "source": [
    "## Cells Cropping and extraction \n",
    "Used after the Yolo model results to further identify the infection stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6ecfdc20-704d-4430-8b30-a5aac47c8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(jsonfiledir, jsonfilename):\n",
    "  import pandas as pd\n",
    "  import numpy as np\n",
    "    \n",
    "  # Extracting txt labels from json file\n",
    "  jsonfiledir = jsonfiledir + '/'\n",
    "  readlocation = jsonfiledir + jsonfilename\n",
    "  json_df = pd.read_json(readlocation)\n",
    "  json_df['path'] = json_df['image'].map(lambda x: jsonfiledir + x['pathname'][1:])\n",
    "  json_df['shape'] = json_df['image'].map(lambda x: x['shape'])\n",
    "\n",
    "  json_object_df = pd.DataFrame([dict(image=c_row['path'], shape=c_row['shape'], **c_item) for _, c_row in json_df.iterrows() for c_item in c_row['objects']])\n",
    "\n",
    "  json_object_df['image_width'] = json_object_df['shape'].map(lambda x: x['c'])\n",
    "  json_object_df['image_height'] = json_object_df['shape'].map(lambda x: x['r'])\n",
    "  json_object_df['image_name'] = json_object_df['image'].map(lambda x: x.split('/', x.count(\"/\"))[-1])\n",
    "  json_object_df['class_label'] = json_object_df['category'].map({'red blood cell': 0, 'leukocyte': 1, 'gametocyte': 2, 'ring': 3, 'trophozoite': 4, 'schizont': 5, 'difficult': 6})\n",
    "\n",
    "  json_object_df['box_x_min'] = json_object_df['bounding_box'].map(lambda x: x['minimum']['c'])\n",
    "  json_object_df['box_x_max'] = json_object_df['bounding_box'].map(lambda x: x['maximum']['c'])\n",
    "  json_object_df['box_y_min'] = json_object_df['bounding_box'].map(lambda x: x['minimum']['r'])\n",
    "  json_object_df['box_y_max'] = json_object_df['bounding_box'].map(lambda x: x['maximum']['r'])\n",
    "\n",
    "  json_object_df['cropped_image_name'] = json_object_df['image_name'].str[:-4] + '_'+ json_object_df.index.astype('str') + json_object_df['image_name'].str[-4:]\n",
    "    \n",
    "  return json_object_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "06f4da29-34df-4fc5-a819-26d448a8610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def crop_images(df, directory):\n",
    "    \n",
    "    newfolder = os.path.join(directory, get_df_name(df))\n",
    "    if not os.path.isdir(newfolder):\n",
    "        os.makedirs(newfolder)\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        im = cv2.imread(row['image'])\n",
    "    \n",
    "        ymin = row['box_y_min'] \n",
    "        ymax = row['box_y_max'] \n",
    "        xmin = row['box_x_min'] \n",
    "        xmax = row['box_x_max']\n",
    "        \n",
    "        cropped_im = im[ymin:ymax, xmin:xmax]\n",
    "    \n",
    "        location = os.path.join(newfolder, row['cropped_image_name'])\n",
    "        cv2.imwrite(location, cropped_im)\n",
    "\n",
    "    \n",
    "    df['cropped_image_path'] = df['cropped_image_name'].map(lambda x: os.path.join(newfolder, x))\n",
    "    temp_df = df[['cropped_image_path', 'cropped_image_name', 'class_label', 'category']]\n",
    "    temp_df.to_csv(directory + '_' + get_df_name(df) + '.csv')\n",
    "    \n",
    "    return newfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c2a3a3-4b99-4ef8-abd6-46a6719fc9bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Balancing & structuring cropped images & dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5e196d75-1f79-49ec-8188-6869840b2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_remove_cat(csvfilepath, removecategorieslist=[]):\n",
    "    cropped_images_df = pd.read_csv(csvfilepath, index=0)\n",
    "    balanced_cropped_df = pd.DataFrame(columns = cropped_images_df.columns)\n",
    "    cropped_removedcategories_df=pd.DataFrame(columns = cropped_images_df.columns)\n",
    "    \n",
    "    if len(removecategorieslist)>0:\n",
    "        cat_list = np.setdiff1d(cropped_images_df['category'].unique(), removecategorieslist)\n",
    "        cropped_removedcategories_df = cropped_images_df[cropped_images_df['category'].isin(removecategorieslist)]\n",
    "    \n",
    "    for cat in cat_list:\n",
    "        temp_df = cropped_images_df[cropped_images_df['category']==cat].sample(n = cropped_images_df['category'].value_counts()[-1], replace=False)\n",
    "        balanced_cropped_df = pd.concat([balanced_cropped_df, temp_df])\n",
    "\n",
    "    return balanced_cropped_df, cropped_removedcategories_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "52595066-69f2-4919-b157-6efcc8f27c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_restructure(df, df_type='train'):\n",
    "    df = df.reset_index()\n",
    "    dir = os.path.split(os.path.split(df.loc[0][1])[0])[0]\n",
    "    dir = os.path.join(dir, 'balanced_cropped_images')\n",
    "    \n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    \n",
    "    if df_type=='train':\n",
    "        dir_suffix = 'train'\n",
    "    elif df_type=='test':\n",
    "        dir_suffix = 'test'\n",
    "    else:\n",
    "        dir_suffix = df_type\n",
    "\n",
    "    df['new_image_path'] = df['cropped_image_path'].map(lambda x: path_update(x, dir))\n",
    "    \n",
    "    df_dir = os.path.join(dir, dir_suffix)\n",
    "    \n",
    "    if not os.path.exists(df_dir):\n",
    "        os.makedirs(df_dir)\n",
    "        for label in df['category'].unique():\n",
    "            class_folder = os.path.join(df_dir, str(label))\n",
    "            if not os.path.exists(class_folder):\n",
    "                os.makedirs(class_folder)\n",
    "                \n",
    "    for i in range(df.shape[0]):\n",
    "        path = df.iloc[i]['cropped_image_path']\n",
    "        pic = path.split('/', path.count(\"/\"))[-1]\n",
    "        piclabel = df.iloc[i]['category']\n",
    "        folder=os.path.join(df_dir, str(piclabel))\n",
    "        shutil.copy2(path, folder)\n",
    "\n",
    "    df.to_csv(os.path.join(os.path.split(df_dir)[0], 'balanced_cropped_'+df_type+'images_table.csv'))\n",
    "    \n",
    "    print(f'Complete. Check results in {dir}') \n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd2089-0847-40c8-83b3-4d734e04a95c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d134fdf9-e75d-4853-a94c-78b5e0b4fde9",
   "metadata": {},
   "source": [
    "#### Functions applicable to all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "09179f65-7cc5-4536-81eb-c6a7e6aeb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compilation(model):\n",
    "    loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "    metrics=['categorical_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.F1Score(), tf.keras.metrics.AUC()]\n",
    "    # metrics = ['accuracy', 'precision', 'recall', 'auc', 'f1score']\n",
    "    \n",
    "    model = model.compile(loss = loss_function, optimizer = 'adam', metrics = metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6fc11433-3d16-4194-8f64-2af967572052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label = 'train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label = 'val' + exp_name)\n",
    "    ax1.set_ylim(0, 5)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['categorical_accuracy'], label='train categorical accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_categorical_accuracy'], label='val categorical accuracy'  + exp_name)\n",
    "    ax2.set_ylim(0, 1.)\n",
    "    ax2.set_title('Categorical Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b54ee0-c455-454d-8a0e-a71b3936a783",
   "metadata": {},
   "source": [
    "#### Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5b5b51be-4a6b-466a-b22d-51e6e572a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_conv_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Rescaling(1/255, input_shape = (250, 240, 3)))\n",
    "    model.add(layers.Conv2D(7, 3, activation = 'relu', padding = 'same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(5, 2, activation = 'relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))   \n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    model.add(layers.Conv2D(3, 2, activation = 'relu'))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dense(6, activation = 'softmax'))\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd915229-1e8d-4fc1-b97f-0a892ebe3f0f",
   "metadata": {},
   "source": [
    "#### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bd69f530-fb76-459e-95c1-560959214153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def set_nontrainable_layers(model):\n",
    "    model.trainable = False  \n",
    "    return model\n",
    "    \n",
    "def updated_vgg16_model():\n",
    "\n",
    "    input = layers.Input(shape = (250, 240, 3))\n",
    "    x = preprocess_input(input)\n",
    "    \n",
    "    vgg16model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "    base_model = set_nontrainable_layers(vgg16model)\n",
    "    \n",
    "    x = base_model(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(100, activation='relu')(x)\n",
    "    output = layers.Dense(6, activation='softmax')(x)\n",
    "    \n",
    "    \n",
    "    # model = Sequential([base_model, flatten_layer, dense_layer, prediction_layer])\n",
    "    model = tf.keras.Model(inputs = input, outputs = output)\n",
    "    \n",
    "    metrics=['categorical_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.F1Score(), tf.keras.metrics.AUC()]\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
